# -*- coding: utf-8 -*-
"""projeto2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L9zaJ5KbYwn_jacWtLOcTlEW1KXzC0RY
"""



import os
import cv2
import glob
from tqdm.notebook import tqdm
import numpy as np
os.listdir("Desktop/Nova pasta")

pip install opencv-python

x_train = []
y_train = []
x_test = []
y_test = []

nome_arquivo = 'Desktop/Nova pasta/train/PNEUMONIA/person63_bacteria_306.jpeg'
img =  cv2.imread(nome_arquivo, cv2.IMREAD_GRAYSCALE)
resized_image = cv2.resize(img, (128, 128))
x_train.append(resized_image)
y_train.append(1)

for i in os.listdir("Desktop/Nova pasta/train/PNEUMONIA/"):
  nome_arquivo = f'Desktop/Nova pasta/train/PNEUMONIA/{i}'
  img =  cv2.imread(nome_arquivo, cv2.IMREAD_GRAYSCALE)
  resized_image = cv2.resize(img, (128, 128))
  x_train.append(resized_image)
  y_train.append(1)

for i in os.listdir("Desktop/Nova pasta/train/NORMAL/"):
  nome_arquivo = f'Desktop/Nova pasta/train/NORMAL/{i}'
  img =  cv2.imread(nome_arquivo, cv2.IMREAD_GRAYSCALE)
  resized_image = cv2.resize(img, (128, 128))
  x_train.append(resized_image)
  y_train.append(0)

for i in os.listdir("Desktop/Nova pasta/test/NORMAL/"):
  nome_arquivo = f'Desktop/Nova pasta/test/NORMAL/{i}'
  img =  cv2.imread(nome_arquivo, cv2.IMREAD_GRAYSCALE)
  resized_image = cv2.resize(img, (128, 128))
  x_test.append(resized_image)
  y_test.append(0)

for i in os.listdir("Desktop/Nova pasta/test/PNEUMONIA/"):
  nome_arquivo = f'Desktop/Nova pasta/test/PNEUMONIA/{i}'
  img =  cv2.imread(nome_arquivo, cv2.IMREAD_GRAYSCALE)
  resized_image = cv2.resize(img, (128, 128))
  x_test.append(resized_image)
  y_test.append(1)

import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
from tensorflow.keras.models  import Sequential

model = Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
# Compilar o modelo
model.compile(optimizer='adam',
loss='binary_crossentropy',
metrics=['accuracy'])

model.fit(np.array(x_train), np.array(y_train), epochs=10, validation_data=(np.array(x_test), np.array(y_test)))

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

y_pred = model.predict(np.array(x_test))

y_pred_classes = np.round(y_pred).astype(int)

y_test_classes = np.array(y_test).astype(int)

accuracy = accuracy_score(y_test_classes, y_pred_classes)
precision = precision_score(y_test_classes, y_pred_classes)
recall = recall_score(y_test_classes, y_pred_classes)
f1 = f1_score(y_test_classes, y_pred_classes)

confusion_matrix = confusion_matrix(y_test_classes, y_pred_classes)

print("Acurácia: {:.2f}".format(accuracy))
print("Precisão: {:.2f}".format(precision))
print("Recall: {:.2f}".format(recall))
print("F1-score: {:.2f}".format(f1))
print("Matriz de Confusão:")
print(confusion_matrix)